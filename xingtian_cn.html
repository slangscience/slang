</head>
 <!-- FlatFy Theme - Andrea Galanti /-->
<!doctype html>
<!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--> <html> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="description" content="NPL Group – Researching in Neuro&Psycho&Lanuage ">
    <meta name="author" content="">

    <title>田兴 - SLANG (Speech, language, and Neuroscience Group)</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
 
    <!-- Custom Google Web Font -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fonts.css" rel="stylesheet">
<!--     <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'> -->
    
    <!-- Custom CSS-->
    <link href="css/general.css" rel="stylesheet">
    
     <!-- Owl-Carousel -->
    <link href="css/custom.css" rel="stylesheet">
    <link href="css/owl.carousel.css" rel="stylesheet">
    <link href="css/owl.theme.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="css/animate.css" rel="stylesheet">

    <!-- markdown -->
    <link href="css/typora_markdown.css" rel="stylesheet">
    
    <!-- Magnific Popup core CSS file -->
    <link rel="stylesheet" href="css/magnific-popup.css"> 
    
    <script src="js/modernizr-2.8.3.min.js"></script>  <!-- Modernizr /-->
    <!--[if IE 9]>
        <script src="js/PIE_IE9.js"></script>
    <![endif]-->
    <!--[if lt IE 9]>
        <script src="js/PIE_IE678.js"></script>
    <![endif]-->

    <!--[if lt IE 9]>
        <script src="js/html5shiv.js"></script>
    <![endif]-->

</head>

<body id="home">
    <!-- Preloader -->
    <div id="preloader">
        <div id="status"></div>
    </div>
    
    <!-- NavBar-->
    <nav class="navbar-default" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand" href="#home">田兴 SLANG</a>
                <img class="main_logo lazy" data-original="img/logo.png">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <li class="menuItem"><a href="index.html">SLANG</a></li>
                    <li class="menuItem"><a href="#top">点击置顶</a></li>
                    <li class="menuItem"><a href="#Research">研究方向</a></li>
                    <li class="menuItem"><a href="#People">组内人员</a></li>
                    <li class="menuItem"><a href="#Publications">发表文章</a></li>
                    <li class="menuItem"><a href="#Teaching">教学概况</a></li>
                    <li class="menuItem"><a href="#Open Positions">职位招募</a></li>
                    <li class="menuItem"><a href="#Resources">研究资源</a></li>
                    <li class="menuItem"><a id="#Contact">联系方式</a></li>
                </ul>
            </div>
           
        </div>
    </nav>

<div id="top" class="content-section-a typora-export">
  <div  id='write'  class = 'is-node'>
    <div class="row">
        <h2>田兴</h2><h5></a>上海纽约大学神经与认知科学助教授</h5>
        <div class="col-md-3">
            <img data-original="img/member/Tian Xing.jpg" alt="" class="img-responsive img-circle lazy"/>
        </div>
        <div class="col-md-offset-4 overview">
            <span class="to_left">言语是我们每天日常交流所使用的最基础、最自然的沟通方式。我们需要频繁的的发音和听声来有效的交流信息，这就要求一个高效的理解声音与制造声音的连接机制。
            通过使用电生理学（脑电/脑磁/经颅脑电）和神经影像学（功能磁共振成像）技术的行为或者计算研究方式，我们想要研究运动感知相互联系（言语理解及产生控制回路中最核心的一环）的功能及其与语言、学习、记忆、想象同其他的高级认知功能的关联。
            更普遍的来说，我把言语和语言作为一个研究模型来探索人类认知的神经计算机制。详细研究情况请参考研究方向的描述。
            </span>
        </div>
    </div>
  </div>
</div> 

<div id="Research" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
      <h2><a name='header-c3959' class='md-header-anchor '></a>研究方向</h2><p class="to_left">概括的来说，我的研究方向是在认知神经科学领域--主要研究人类认知功能的神经机制。其包括至少两个主要研究方向：神经的表征和计算。神经的表征是指信息是如何在我们大脑中表征的；而神经计算是指神经的表征是如何形成和改变的。我认为存在一种通用普遍的神经计算机制，称作<strong>典型神经计算</strong>，其可以应用到不同的模态和认知领域的信息处理中。<strong>我在我自己的研究中使用言语和语言来作为模型去探索反应人类认知功能的典型神经计算</strong>两种神经计算方式最为主要：</p><ul><li><p class="to_left"><strong>转化</strong>:</p><p class="to_left">Variables or representation change over time and/or across brain functional regions. The focus is motor-to-sensory transformation and its functionality on(speech and language) behavior, which includes its putative computational function in the following research topics:</p><ul><li><strong>Speech production and control:</strong> The high computational demand of speech (e.g., producing 4-8 syllable per second) needs an efficient way to provide control. I have proposed a motor-to-sensory transformation in a sequential manner for speech control (fig. 1), and a series of studies have been carried out to test the proposed model. Many aspects and questions still need to be addressed. For example, whatare the computational roles of motor-to-sensory transformation in speech control? And what are the neural mechanisms and implementation? </li><li><strong>Perception</strong>: One theory that links motor and perception is the motor theory of speech perception and language comprehension. Numerous studies have observed activity in motorregions while listening to speech or reading words (verbs) and sentences. Butthe function of motor activation during perception is still debated. Canmotor-to-sensory transformation offer a mechanistic account for these data and explain why motor regions are engaged during perception? Ultimately, can motor-to-sensory transformation address the invariance problem in speechperception? </li><li><strong>Learning</strong>:  Second language (L2) and bilingualism are our focus. Learning, especially for speech essentially creates a perception-action mapping – which requires the reproduction of sound patterns with certain meanings. So, do L2 learningrecruit motor-to-sensory transformation? How do the representational changes between languages engage the motor-to-sensory transformation in bilinguals? </li><li><strong>Memory, mental imagery,and other higher order cognitive function</strong>: Bothmotor-to-sensory transformation and memory retrieval can induce internal neuralrepresentation without external stimulation (fig. 2). How do they differ? Whatare their functional specificity, especially in speech and language? Moreover, how do the internally induced neural representation link to our subjective feeling of imagination?</li><li><strong>For special populations</strong>: Can motor-to-sensory transformation be the underlying mechanism for the positive symptoms in special populations, such as those with speech and language deficits (e.g., stuttering, dyslexia), and those with mental and neural disorders (e.g., auditory hallucination in schizophrenia, also see point 6 below)? </li><li><strong>Agency and self-monitoring</strong>: How can we have body ownership (knowing our body is ours and under our control, incontrast to cases like rubber hand illusion and phantom limb sensation), and identify incoming stimulation as generated by ourselves (e.g. speech feedback is produced by me, in contrast to cases like auditory hallucination)? Can motor-sensory transformation in combination with perception provide us agency andself-monitoring function? (See section II. Integration for more details.) </li></ul></li><li><p class="to_left"><strong>Integration</strong>: </p><p class="to_left">   Combining information across time, locations, or modalities, usually creates new representations. My research focus in this direction is on temporal integration(mostly with my collaborators) and multi-modal integration:</p><ul><li><p class="to_left"><strong>Temporal integration </strong>(collaborating with Nai Ding, Xiangbin Teng, and David Poeppel):
      Similar kinds of information are summarize over time (e.g., sounds, written words, and their following linguistic processes). One theory proposed that neural oscillations may serve as an integrative function during speech perception (may come with a figure like Jinbiao’s reading experiment – Yi3 Yi4 Dai4 Lao2, in Nai’s formatwith additional acoustic waveforms). How do the neural oscillations mediate the integrative process, as well as speech perception and language comprehension? (How do the proposed neural oscillations relate to memory 2013 curr bio and 2015 sci report?) [integration and process of before and after] e.g.(retrieval) integration and comparison, as well as later evaluation process(N400) ?</p></li><li><p class="to_left"><strong>Multi-modal integration</strong>: Informationfrom different sources are combined together. The common kind of multi-modalintegration is multisensory integration (e.g., visual-auditory integration – looking at a person’s face while listening to speech). I am particularly interested in how motor and other cognitive functions integrate, and thefunction of such integration. This multi-modal integration differs from thecommon multisensory integration in that it does not require information coming from external sources. Instead, the information can be induced internally, suchas via motor-to-sensory transformation. For example, </p><p class="to_left">   ​    1) how does the motor-to-sensory transformation integrate with external feedback for speech control? What would the computation be when they are (temporally, spectrally, or spatially) inconsistent?</p><p class="to_left">   ​    2) How are the senses of agency and function of self-monitoring obtained by integrating motor-to-sensory transformation andsensory feedback? </p><p class="to_left">   ​    3) Can motor-to-sensory transformation integrate with other information to create new (episodic and semantic) memory? </p></li></ul></li></ul><p class="to_left">I am also interested in cross-disciplinary research, such as between neuroscience and computer science. By collaborating with faculty in computer science (ZhengZhang and Xipeng Qiu), we are aiming to build a bridge between artificial intelligence (AI) and human intelligence in the areas of speech and language. For example, we investigate the commonality between natural language processing and neural bases of language processing, especially in the aspect of semantics. Moreover, we would like to use recurrent neural network models to test neuroscience theories and models, such as lateralization and motor-to-sensory transformation.The purpose of this endeavor is to advance both fields – borrow methods andmodels from computer science to understand our brain better, while lending neuroscience findings, and models to make AI smarter and more human-like. </p>
  </div>
</div>

<div id="People" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write' class = 'is-node'>
    <h2><a name='header-c4011' class='md-header-anchor '></a>组内人员</h2><h4><a name='header-c4012' class='md-header-anchor '></a>PI</h4><ul><li>田兴(<a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a>)<br>上海纽约大学神经与认知科学助教授</li></ul><h4><a name='header-c4018' class='md-header-anchor '></a>研究助理</h4><ul><li>朱昊</li><li>李炎烛</li><li>沈云云</li><li>Anna Zhen</li></ul><h4><a name='header-c4026' class='md-header-anchor '></a>博士后研究员</h4><ul><li>刘晓峦</li><li>张文嘉</li></ul><h4><a name='header-c4031' class='md-header-anchor '></a>学生</h4><ul><li>王玲婷 (ECNU-NYU)</li><li>马欧 (ECNU-NYU)</li><li>李思齐 (ECNU-NYU)</li><li>施赛男 (ECNU-NYU)</li><li>杨馥银(ECNU-NYU)</li></ul><h4><a name='header-c4036' class='md-header-anchor '></a>本科生／实习生</h4><ul><li>Tehreem Nihar (NYUSH)</li><li>Tianyi Bill Zheng (NYUSH, co-advisingwith Zheng Zhang)</li></ul><h4><a name='header-c4050' class='md-header-anchor '></a>校友</h4><ul><li>白帆(Radbound Univeristy)</li><li>杨金骉(Radbound Univeristy)</li><li>徐启慧(Hunter college)</li><li>Danfeng Wu (MIT)</li><li>Stella Yuan (Carnegie Mellon University) </li></ul><h4><a name='header-c4062' class='md-header-anchor '></a>合作者</h4><ul><li>蔡清 (ECNU) </li><li>张峥 (NYU Shanghai) </li><li>Diogo Almeida (NYU Abu Dhabi) </li><li>丁萘 (Zhe Jiang University) </li><li>罗欢 (Peking University) </li><li>Lucia Melloni (NYU and Max-Planck) </li><li>腾相斌 (NYU and Max-Planck) </li><li>王茜 (San Bo Hospital)</li></ul>
  </div>
</div>

<div id="Publications" class="content-section-a" style="border-top: 0">
        <div class="container">
            <div class="col-md-6 col-md-offset-3 text-center wrap_title">
                <h2>发表文章</h2>               
            </div>
            <div class="row">
                <div class="col-md-12 wrap_title">
                    <h3>发表中</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left">Tian, X., Ding, N., Teng, X., Bai F., &amp;Poeppel, D. (in press). Imagined speech influences perceived loudness of sound.<em> Nature Human Behavior.</em></p></blockquote>
                    </div>

                    <h3>2017</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/Concurrent temporal channels for auditory processing.pdf">Teng, X., Tian, X., Rowland, J.,&amp;Poeppel, D. (2017). Concurrent temporal channels for auditory processing: Oscillatory neural entrainment reveals segregation of function at different scales. <em> PLoS biology</em>, 15(11), e2000812.</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Theta band oscillations reflect more than entrainment.pdf">Teng, X., Tian, X., Doelling, K., &amp;Poeppel, D. (2017). Theta band oscillations reflect more than entrainment: behavioral and neural evidence demonstrates an active chunking process. <em>European Journal of Neuroscience.</em></a></p></blockquote>

                    <h3>2016</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/Testing multi-scale processing in the auditory system.pdf">Teng, X., Tian, X., &amp; Poeppel, D.(2016). Testing multi-scale processing in the auditory system. <em>Scientific Reports</em>, 6, 34390. doi:10.1038/srep34390</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Rule based and word level statistics based processing of language.pdf">Ding, N., Melloni, L., Tian, X., &amp;Poeppel, D. (2016). Rule-based and word-level statistics-based processing of language: insights from neuroscience. <em>Language,Cognition and Neuroscience</em>, 1-6. doi: 10.1080/23273798.2016.1215477</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Mental imagery of speech implicates two mechanisms of perceptual reactivation.pdf">Tian, X., Zarate, J.M., Poeppel, D.(2016). Mental imagery of speech implicates two mechanisms of perceptual reactivation. <em>Cortex</em>. 77, 1-12. doi: 10.1016/j.cortex.2016.01.002</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Cortical tracking of hierarchical linguistic structure in connected speech.pdf">Ding, N., Melloni, L., Zhang, H., Tian,X., Poeppel, D. (2016). Cortical tracking of hierarchical linguistic structure in connected speech. <em>Nature Neuroscience</em>.19(1), 158-164.</a></p></blockquote>
                    </div>

                    <h3>2015</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/Dynamics of self-monitoring and error detection in speech production.pdf">Tian, X., &amp; Poeppel, D. (2015). Dynamics of self-monitoring and error detection in speech production: evidence from mental imagery MEG.  <em>Journal of Cognitive Neuroscience.</em> 27(2), 352-364.</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Multiple levels of linguistic and paralinguistic features contribute to voice recognition.pdf">Zarate, J.M.<em>, Tian, X.</em>, Woods, K.J.P.,&amp; Poeppel, D. (2015). Multiple levels of linguistic and paralinguistic features contribute to voice recognition. <em>Scientific Reports</em>. 5: 11475. doi: 10.1038/srep11475 (*equal contribution)</a></p></blockquote>
                    </div>

                    <h3>2013</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/The effect of imagination on stimulation.pdf">Tian, X., &amp; Poeppel, D. (2013). The effect of imagination on stimulation: the functional specificity of efference copies in speech processing.  <em>Journal of Cognitive Neuroscience.</em> 25(7), 1020-1036.</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Neural response phase tracks how listeners learn new acoustic representations.pdf">Luo<em>, H., Tian</em>, X., Song, K., Zhou, K., &amp; Poeppel, D. (2013). Neural response phase tracks how listeners learn new acoustic representations. <em>Current Biology</em>. 23(11), 968–974.(*equal contribution)</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Change detection through connectivity reduction.pdf">Tian, X., &amp; Huber, D.E. (2013). Playing ‘Duck Duck Goose’ with neurons: Change detection through connectivity reduction. <em>Psychological Science</em>.24(6), 819–827.</a></p></blockquote>
                    </div>

                    <h3>2012</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/Mental imagery of speech linking motor and sensory systems through internals imulation.pdf">Tian, X., &amp; Poeppel, D. (2012). Mental imagery of speech: linking motor and sensory systems through internals imulation. <em>Front. Hum. Neurosci.</em> 6:314. doi: 10.3389/fnhum.2012.00314</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/The effects of visual imagery on face identification.pdf">Wu, J., Duan, H., Tian, X., Wang, P.,&amp; Zhang, K. (2012). The effects of visual imagery on face identification: an ERP study. <em>Front. Hum. Neurosci.</em> 6:305. doi: 10.3389/fnhum.2012.00305</a></p></blockquote>
                    </div>

                    <h3>2011</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/A habituation account of change detection different judgments.pdf">Davelaar, E.J., Tian, X., Weidemann, C.T., &amp; Huber, D.E. (2011). A habituation account of change detection insame/different judgments. <em>Cognitive,Affective and Behavioral Neuroscience</em>, 11,608-626.</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/TopoToolbox.pdf">Tian, X., Poeppel, D., &amp; Huber, D.E. (2011). TopoToolbox: Using sensor topography to calculate psychologically meaningful measures from event-related EEG/MEG. <em>Computational Intelligence and Neuroscience</em>. 2011,doi:10.1155/2011/674605</a></p></blockquote>
                    </div>

                    <h3>2010</h3>
                    <blockquote><p class="to_left"><a href="papers/Mental imagery of speech andmovement implicates the dynamics of internal forward models.pdf">Tian, X., &amp; Poeppel, D. (2010). Mental imagery of speech andmovement implicates the dynamics of internal forward models. <em>Front. Psychology,</em> 1:166. doi: 10.3389/fpsyg.2010.00166</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/Testing an associative account of semantic satiation.pdf">Tian, X., &amp; Huber, D.E. (2010). Testing an associative account of semantic satiation. <em>Cognitive Psychology,60</em>, 267-290.</a></p></blockquote>
                    </div>

                    <h3>2008</h3>
                    <div class="list-group">
                    <blockquote><p class="to_left"><a href="papers/Measures of spatial similarity and response magnitude in MEG andscalp EEG.pdf">Tian, X., &amp; Huber,D.E. (2008). Measures of spatial similarity and response magnitude in MEG andscalp EEG. <em>Brain Topography</em>, <em>20</em>,131-141.</a></p></blockquote>
                    <blockquote><p class="to_left"><a href="papers/The Dynamics of Integration and Separation.pdf">Huber, D. E., Tian, X., Curran, T., O’Reilly, C, &amp; Woroch, B. (2008). The dynamics of integration and separation: ERP, MEG, and neural network studies of immediate repetition effects. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, 34,1389-1416.</a></p></blockquote>
                    </div>
                </div>
            </div>  
        </div>
    </div>

<div id="Teaching" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4146' class='md-header-anchor '></a>教学概况</h2><h3><a name='header-c4147' class='md-header-anchor '></a>课程</h3><ul><li>本科, Behavioral and Integrative Neuroscience, 上海纽约大学 2016</li><li>本科, Neural Bases of Speech and Language, 上海纽约大学 2015, 2016, 2017</li></ul><h3><a name='header-c4153' class='md-header-anchor '></a>客座讲座</h3><ul><li>“Speech perception and production”, Cognitive Neuroscience, 认知神经科学研究所, 华东师范大学 2016</li><li>“Neural computation in speech”, Frontiers in Cognitive Neuroscience research, 认知神经科学研究所, 华东师范大学 2016</li><li>“Language”, Behavioral and Integrative Neuroscience (by Clayton Curtis), Neuroscience program, 上海纽约大学 2015</li><li>“MEG fundamentals”, Laboratory in Cognitive Neuroscience (by David Poeppel), Department of Psychology, 纽约大学 2012</li><li>“Testing psychological theories using electrophysiological methods”, Cognitive Neuroscience (by Zoran Josipovic), Department of Psychology, 纽约大学 2012</li></ul>
  </div>
</div>
<div id="Open Positions" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4175' class='md-header-anchor '></a>职位招募</h2><ul><li><h3><a name='header-c4178' class='md-header-anchor '></a>博士后研究员</h3><p class="to_left">多个职位接受应聘。有关信息可以在<a href="http://shanghai.nyu.edu/about/work/fellowships" style="color:#239B56">此网页</a>查看。如有兴趣，请将应聘信息发送给我。</a></p></li><li><h3><a name='header-c4182' class='md-header-anchor '></a>研究生／博士生</h3><p class="to_left">作为学生申请加入我们实验室有两种方法，一是通过纽约大学神经科学上海博士生招生计划，另一是通过华东师范大学脑与认知科学研究生招生计划。详细信息请在<a href="http://neuro.shanghai.nyu.edu/graduate" style="color:#239B56">此网页</a>查看。想要申请的同学请联系我。</a></p></li><li><h3><a name='header-c4186' class='md-header-anchor '></a>在读本科生／实习生</h3><p class="to_left">我们研究小组向想要积极参与人类认知功能（语音，语言，学习，记忆等高级认知功能）研究工作和学习的本科学生开放。想要参与的同学可以在学期中或者假期申请。请将你的简历，自我研究兴趣简介，以及一份非正式成绩单发送给我。</a>.</p></li></ul>
  </div>
</div>
<div id="Resources" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4192' class='md-header-anchor '></a>研究资源</h2><ul><li><h3><a name='header-c4195' class='md-header-anchor '></a>Topo Toolbox</h3><p class="to_left"><em>点此下载 <a href="files/TopoToolbox.zip">ZIP</a> 文件，包含主要函数、详细教程、使用手册和样本数据。教程和使用手册也可以分别下载： <a href="files/TopoToolbox tutorial.pdf">教程</a>, <a href="files/TopoToolbox manual.pdf">使用手册</a>. </em></p></li></ul><p class="to_left">TopoToolbox是一个开源的软件，致力于解决事件相关脑电／脑磁数据的拓扑分析，基于Tian和Huber（2008；2011）提出的方法。TopoToolbox为研究者提供了一个直接获取有关于拓扑性反应相关性以及由在传感器位置上的电磁信号产生的心理意义反应量级的准确测量的工具。这些分析在无解剖学描述的情况下验证心理学理论极为实用。
    此软件主要提供以下三个功能：</p><ol start='' ><li><p class="to_left">角度测量：测量不同实验条件中，topo的相似度。</p></li><li><p class="to_left">投射测量：以一个标准样板规格化个体差异来测量反应程度。 </p></li><li><p class="to_left">角度力学测量：评估时间线上的模式相似度。
    此软件由Dr. Xing Tian, Dr. David Poeppel 和 Dr. David E. Huber共同开发. 其需要MATLAB平台运行，支持多种标准数据格式。请注明引用当您使用该软件用来发表文章：</p><blockquote><p class="to_left">Tian, X., &amp; Huber, D. (2008). Measures of spatial similarity and response magnitude in MEG and scalp EEG. <em>Brain Topography, 20</em>(3), 131-141.</p></blockquote><blockquote><p class="to_left">Tian, X., Poeppel, D., &amp; Huber, D.E. (2011). TopoToolbox: Using sensor topography to calculate psychologically meaningful measures from event-related EEG/MEG. <em>Computational Intelligence and Neuroscience</em>, 2011. doi:10.1155/2011/674605</p></blockquote></li></ol><p class="to_left">如果您有任何问题或者建议，请联系我，邮箱：<a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p>
  </div>
</div>

<div id="Contact" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4222' class='md-header-anchor '></a>联系方式</h2><p class="to_left">欢迎感兴趣的学生，博士后研究人员及合作者来直接与我联系。</p><p class="to_left">田兴
    邮箱: <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p><ul><li>浦东校区:
    中国上海市浦东新区世纪大道1555号1138室，邮编: 200122
    办公室电话: +86 (21) 20595201 </li><li>浦西华东师范大学中北校区:
    中国上海市普陀区华东师范大学中山北路3663号地理楼140室，邮编：200062
    办公室电话: +86(21)20595996</li></ul>
  </div>
</div>


    <!-- Contact -->
    <footer>
        <div class="container">
            <h5>Copyright (c) 2017 Speech, language, and Neuroscience Group. Built by Jinbiao(Ray) Yang,Updated by Hao Zhu using the theme based on <a href="https://github.com/andreagalanti/Flatfy-Free-Flat-and-Responsive-HTML5-Template">Flatfy</a>.</h5>
                <li></li>
            
        </div>
    </footer>
    <!-- keep the navbar fixed-->
    <div class="morph-button morph-button-inflow morph-button-inflow-1">
        <button type="button "></button>
    </div>
    <!-- JavaScript -->
    <script src="js/jquery.min.js"></script>
    <script src="js/jquery.lazyload.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/owl.carousel.js"></script>
    <script src="js/script.js"></script>
    <!-- StikyMenu -->
    <script src="js/stickUp.min.js"></script>
    <script type="text/javascript">
      jQuery(function($) {
        $(document).ready( function() {
          $('.navbar-default').stickUp();
          $(".tooltip-options").tooltip({html : true });
        });
      });

      $(function() {
        $("img.lazy").lazyload();
    });

      $('#internal').click(function(){
            var internal = window.prompt("Please enter the password:", "");
            if(internal.length>0){window.location.href = internal+'.html';} 
        });
    </script>
    <!-- Smoothscroll -->
    <script type="text/javascript" src="js/jquery.corner.js"></script> 
    <script src="js/wow.min.js"></script>
    <script>
     new WOW().init();
    </script>
    <script src="js/classie.js"></script>
    <script src="js/uiMorphingButton_inflow.js"></script>
    <!-- Magnific Popup core JS file -->
    <script src="js/jquery.magnific-popup.js"></script> 
</body>

</html>

</html>